# -*- coding: utf-8 -*-
"""DL visual hw1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ErVnf76-GpTd7_GfVT0FYZgKd2e0_r6s
"""

import os
os.chdir('/home/u9285752/')

# !pip install albumentations==0.4.6

import sys
import os
import torch
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from PIL import Image
from torch import nn, optim
from torch.nn import functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split, StratifiedKFold
import torchvision.models as models
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2
import random
import copy

def find_dir(path):
  for fd in os.listdir(path):
    full_path = os.path.join(path, fd)
    if os.path.isdir(full_path):
      # print('資料夾:',full_path)
      find_dir(full_path)
    else:
      # print('檔案:',full_path)
      data_path.append(full_path)

data_path = []
path = './2021VRDL_HW1_datasets/training_images'
find_dir(path)
image_list = data_path

image_list[0:3]
sorted(image_list)[0:3]

"""# Read Label"""

img_label = {}
with open('./2021VRDL_HW1_datasets/training_labels.txt','r') as f:
    for line in f.readlines():
        line = line.strip('\n')
        split_line = line.split(' ')
        img_name = split_line[0]
        label = split_line[1].split('.')[0]
        if img_name not in img_label:
            img_label[img_name] = label
            
print(len(img_label))

all_labels = []
for i in sorted(img_label.keys()):
  all_labels.append(img_label[i])
print(sorted(img_label.keys())[0],all_labels[0])

"""# Get validation acc"""

def get_acc(loader, model, epoch):
    model.eval()
    count = 0
    correct = 0
    test_loss = 0
    plt.figure(figsize=(12.0, 6.0))
    plt.rcParams['savefig.dpi'] = 200
    plt.rcParams['figure.dpi'] = 200
    for step, (batch) in enumerate(loader):
        images, labels = [t.to(device) for t in batch]
        nodes_2, logits = model(images)
        loss = criterion(logits, labels)
        test_loss += loss.item()
        topv, topi = logits.topk(1)  #max,index
        for predict, label in zip(topi.tolist(), labels.tolist()):
            if predict[0] == label:
                correct += 1
            count += 1
    return correct / count, test_loss / (step + 1)

def draw_chart(chart_data, outfile_name):
    # -------------- draw loss image --------------
    # -------------- new one figure and set resolution --------------
    plt.figure(figsize = (12.0, 6.0))
    plt.rcParams['savefig.dpi'] = 200
    plt.rcParams['figure.dpi'] = 200
    # -------------- plot data in image --------------
    plt.plot(chart_data['epoch'], chart_data['train_loss'], label = 'train_loss')
    plt.plot(chart_data['epoch'], chart_data['val_loss'], label = 'val_loss')
    # -------------- draw underline --------------
    plt.grid(True, axis = "y", ls = '--')
    # -------------- draw legent --------------
    plt.legend(loc =  'best')
    # -------------- show lable --------------
    plt.xlabel('epoch', fontsize = 20)
    # plt.yticks(np.linspace(0,1,11))
    plt.savefig('./' + outfile_name + str(fold) + '_loss_.jpg')
    plt.close('all')
    # --------------

    plt.figure(figsize=(12.0, 6.0))
    plt.rcParams['savefig.dpi'] = 200
    plt.rcParams['figure.dpi'] = 200
    plt.plot(chart_data['epoch'], chart_data['val_acc'], label = 'val_acc')
    plt.plot(chart_data['epoch'], chart_data['train_acc'], label = 'train_acc')
    plt.grid(True,axis = "y",ls = '--')
    plt.legend(loc = 'best')
    plt.xlabel('epoch', fontsize=20)
    # plt.yticks(np.linspace(0,1,11))
    plt.savefig('./' + outfile_name + str(fold) + '_val_acc_.jpg')
    plt.close('all')
    with open('./' + outfile_name + '.json','w') as file_object:
        json.dump(chart_data,file_object)

def get_mean_and_std(dataset):
    '''Compute the mean and std value of dataset.'''
    dataloader = trainloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)

    mean = torch.zeros(3)
    std = torch.zeros(3)
    print('==> Computing mean and std..')
    for inputs in dataloader:
        inputs = np.array(inputs)
        for i in range(3):
            mean[i] += (inputs[0][:,i,:,:]*1.0).mean()
            std[i] += (inputs[0][:,i,:,:]*1.0).std()
    mean.div_(len(dataset))
    std.div_(len(dataset))
    return mean, std

"""# Training"""

class BirdDataset(Dataset):

    def __init__(self, data, labels, train, transform = None):
        self.df = data
        self.labels = labels
        self.train = train
        self.transform = transform

    def __getitem__(self, index): 
        image = cv2.imread(self.df[index])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image_tensor = self.transform(image = image)
        label_tensor = torch.tensor(int(self.labels[index])-1)
        
        # -------------- check transform of images --------------
        # transforms.ToPILImage()(image_tensor).convert('RGB').save('./'+image_name)
        return image_tensor['image'], label_tensor

    def pad_batch(self, batch):
        # collate_fn for Dataloader, pad sequence to same length and get mask tensor
        if batch[0][1] is not None:
            (image_tensor, label_tensor) = zip(*batch)
            images = torch.stack(image_tensor)
            labels = torch.stack(label_tensor)
        else:
            (image_tensor) = zip(*batch)
            images = torch.stack(image_tensor)
        return images, labels

    def __len__(self):
        return len(self.df)

train_transform = A.Compose([
       A.RandomResizedCrop(height = 299, width = 299),
       A.RGBShift(r_shift_limit = 15, g_shift_limit = 15, b_shift_limit = 15, p = 0.5),
       A.augmentations.transforms.HorizontalFlip(p = 0.5),
       A.ShiftScaleRotate(shift_limit = 0.05, scale_limit = 0.05, rotate_limit = 20, p = 0.5),
       A.Normalize(mean = [123.2744/255, 126.9946/255, 109.6768/255], std = [47.8842/255, 47.4675/255, 50.7484/255], max_pixel_value = 255.0, p = 1.0),
       ToTensorV2(),
    ])
val_transform = A.Compose(
    [   
       A.Resize(375,375),
       A.CenterCrop(299,299),
       A.Normalize(mean = [123.2744/255, 126.9946/255, 109.6768/255], std = [47.8842/255, 47.4675/255, 50.7484/255], max_pixel_value = 255.0, p = 1.0),
        ToTensorV2(),
    ])

def visualize_augmentations(dataset, idx = 0, samples = 10, cols = 5):
    dataset = copy.deepcopy(dataset)
    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])
    rows = samples // cols
    figure, ax = plt.subplots(nrows = rows, ncols = cols, figsize = (12, 6))
    for i in range(samples):
        image, _ = dataset[idx]
        ax.ravel()[i].imshow(image)
        ax.ravel()[i].set_axis_off()
    plt.tight_layout()
    plt.show()

class FocalLoss(nn.modules.loss._WeightedLoss):
  def __init__(self, weight = None, gamma = 4, reduction = 'mean'):
        super(FocalLoss, self).__init__(weight, reduction = reduction)
        self.gamma = gamma
  def forward(self, input, target):
        ce_loss = F.cross_entropy(input, target, reduction = self.reduction, weight = self.weight)
        pt = torch.exp(-ce_loss)
        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()
        return focal_loss

class densenet_model(nn.Module):
    def __init__(self, numClasses = 200):
        super(densenet_model, self).__init__()   
        model_densenet = models.densenet161(pretrained=True)
        self.densenet = model_densenet
        for param in model_densenet.parameters():
            param.requires_grad = True
        num_ftrs = self.densenet.classifier.in_features
        self.densenet.classifier = nn.Sequential(
                                       nn.Linear(num_ftrs,1024),
                                       nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1),
                                       nn.ReLU(),
                                       nn.Dropout(0.3),
                                       nn.Linear(1024, 200)
                                       )
    def forward(self, x):
        logits = self.densenet(x)
        node_2 = x.view(x.size(0),-1)
        return node_2, logits

skf = StratifiedKFold(n_splits=5,random_state=42, shuffle=True)

if __name__ == '__main__':
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(device)

    # -------------- hyper parameter --------------
    batch_size =  64
    learning_rate = 0.005
    model_name = 'CNN_model'
    # ------------------------------------------

    # -------------- prepare training and testing data --------------
    data = sorted(image_list)
    for fold, (train_idx, test_idx) in enumerate(skf.split(data, all_labels)):
      train_data = []
      valid_data = []
      train_labels = []
      valid_labels = []
      img_label = {}
      for i in train_idx:
        train_data.append(data[i])
        train_labels.append(all_labels[i])
      for i in test_idx:
        valid_data.append(data[i])
        valid_labels.append(all_labels[i])
      train_set = BirdDataset(train_data, train_labels, train=True, transform = train_transform)
      valid_set = BirdDataset(valid_data, valid_labels, train=False, transform = val_transform)
      visualize_augmentations(train_set)
      visualize_augmentations(valid_set)
      train_loader = DataLoader(train_set, batch_size=batch_size, collate_fn = train_set.pad_batch, shuffle=True)
      valid_loader = DataLoader(valid_set, batch_size=1, collate_fn = valid_set.pad_batch)
      #----------------------------------------------------------------

      # -------------- init model --------------
      model = densenet_model()
      # model.load_state_dict(torch.load('./' + model_name + str(fold) + '_.pkl'))
      model = model.to(device)
      #------------------------------------------

      # -------------- create optimizer and loss function --------------
      optimizer = torch.optim.SGD(filter(lambda x: x.requires_grad, model.parameters()), lr = learning_rate, momentum = 0.9, weight_decay = 1e-5)
    
      scheduler = optim.lr_scheduler.StepLR(optimizer = optimizer, step_size = 2, gamma = 0.94)

      criterion = FocalLoss()
      # -------------- init data for image --------------
      chart_data={"train_loss":[], "val_loss":[], "val_acc":[], "train_acc":[], "val_recall":[], "train_recall":[], "epoch":[]}
      #--------------------------------------------------------
      max_acc = 0

      print('fold: '+ str(fold))

      for epoch in range(80):
          train_loss = 0
          count = 0
          correct = 0
          model.train()
          optimizer.zero_grad()
          for step, (batch) in enumerate(train_loader):
              images, labels = [t.to(device) for t in batch]
              node_2, logits = model(images)
              topv, topi = logits.topk(1) 
              for predict, label in zip(topi.tolist(), labels.tolist()):
                  if predict[0] == label:
                      correct+=1
                  count += 1

              # -------------- caculate loss and update para --------------
              model.zero_grad()
              loss = criterion(logits, labels)
              train_loss += loss.item() #take out the loss number
              loss.backward()
              optimizer.step()
#           scheduler.step()
              # --------------------------------------------------------

          # -------------- get test data's acc --------------
          v_acc, val_loss = get_acc(valid_loader, model, epoch)
          if v_acc > max_acc :
              max_acc = v_acc
              torch.save(model.state_dict(), './' + model_name + str(fold) + '.pkl')
          # --------------------------------------------------------
          
          print('{} scheduler: {}'.format(epoch + 1, scheduler.get_last_lr()[0]))
          print('Epoch: ' , str(epoch) , \
                  '\ttrain_loss: ' + str(round(train_loss / (step + 1), 5)),\
                  '\ttrain_acc: ' + str(round(correct / count, 4)),\
                  '\tvalid_loss: ' + str(round(val_loss, 5)),\
                  '\tval_acc: ' + str(round(v_acc, 4)) \
              )

          # -------------- store data for image  --------------
          chart_data['epoch'].append(epoch)
          chart_data['train_loss'].append(train_loss / (step + 1))
          chart_data['val_loss'].append(val_loss)
          chart_data['train_acc'].append(correct / count)
          chart_data['val_acc'].append(v_acc)
          draw_chart(chart_data, model_name)
